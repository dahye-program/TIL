# OS(Operating System)

## 프로세스와 스레드

### 프로세스(Process)

- 실행 중인 프로그램
- 디스크로부터 메모리에 적재되어 CPU 의 할당을 받을 수 있는 것
- 운영체제로부터 주소 공간, 파일, 메모리 등을 할당받음 ⇒ 총칭하여 프로세스라고 함
- 함수의 매개변수, 복귀 주소와 로컬 변수와 같은 임시 자료를 갖는 프로세스 스택과 전역 변수들을 수록하는 데이터 섹션을 포함
- 프로세스 실행 중에 동적으로 할당되는 메모리인 힙을 포함

### **프로세스 제어 블록(Process Control Block, PCB)**

- 특정 **프로세스에 대한 중요한 정보를 저장** 하고 있는 운영체제의 자료구조
- 운영체제는 프로세스를 관리하기 위해 **프로세스의 생성과 동시에 고유한 PCB 를 생성**
- 프로세스는 CPU를 할당받아 작업을 처리하다가도 프로세스 전환이 발생하면 진행하던 작업을 저장하고 CPU를 반환해야 하는데, 이때 작업의 진행 상황을 모두 PCB 에 저장함
- 그리고 다시 CPU를 할당받게 되면 PCB에 저장되어있던 내용을 불러와 이전에 종료됐던 시점부터 다시 작업을 수행함

**_PCB 에 저장되는 정보_**

- 프로세스 식별자(Process ID, PID) : 프로세스 식별 번호
- 프로세스 상태 : new, ready, running, waiting, terminated 등의 상태를 저장
- 프로그램 카운터 : 프로세스가 다음에 실행할 명령어의 주소
- CPU 레지스터
- CPU 스케쥴링 정보 : 프로세스의 우선순위, 스케줄 큐에 대한 포인터 등
- 메모리 관리 정보 : 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함
- 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들과 열린 파일 목록
- 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호 등

### **스레드(Thread)**

- 스레드는 프로세스의 실행 단위라고 할 수 있음
- 한 프로세스 내에서 동작되는 여러 실행 흐름으로 프로세스 내의 주소 공간이나 자원을 공유할 수 있음
- 스레드는 스레드 ID, 프로그램 카운터, 레지스터 집합, 그리고 스택으로 구성
- 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 그리고 열린 파일이나 신호와 같은 운영체제 자원들을 공유
- 하나의 프로세스를 다수의 실행 단위로 구분하여 자원을 공유하고 자원의 생성과 관리의 중복성을 최소화하여 수행 능력을 향상시키는 것을 멀티스레딩이라고 함
  - 이 경우 각각의 스레드는 독립적인 작업을 수행해야 하기 때문에 각자의 스택과 PC 레지스터 값을 갖고 있음

### **스택을 스레드마다 독립적으로 할당하는 이유**

스택은 함수 호출 시 전달되는 인자, 되돌아갈 주소값 및 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능하다는 것이고 이는 독립적인 실행 흐름이 추가되는 것이다.

따라서 스레드의 정의에 따라 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당한다.

### **PC Register를 스레드마다 독립적으로 할당하는 이유**

PC 값은 스레드가 명령어의 어디까지 수행하였는지를 나타나게 된다.

스레드는 CPU 를 할당받았다가 스케줄러에 의해 다시 선점당한다.

때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.

따라서 PC 레지스터를 독립적으로 할당한다.

### 프로세스 상태

- **생성(create)** : 프로세스가 메모리에 올라와 실행 준비를 완료한 상태, 프로세스를 관리하는데 필요한 프로세스 제어 블록(PCB) 생성
- **준비(ready)** : 생성된 프로세스가 CPU를 얻을 때까지 기다리는 상태
- **실행(running)** : 준비 상태에 있는 프로세스 중 하나가 CPU를 얻어 실제 작업을 수행하는 상태, `execute state` 라고도 표현, 만약 주어진 시간을 다 사용하고도 작업이 끝나지 않으면 다시 준비 상태로 돌아와 다음 차례를 기다림
- **대기(blocking)** : 입출력을 요구한 프로세스가 입출력이 완료될 때 까지 기다리는 상태, 작업의 효율성을 높이기 위해 대기 상태로 옮김
- **완료(terminate)** : 실행 상태의 프로세스가 주어진 시간 동안 작업을 마치면 완료 상태가 됨, 프로세스 제어 블록이 사라진 상태 의미

### 디스패치(dispatch)

- 준비 상태의 프로세스 중 하나를 골라 실행 상태로 바꾸는 CPU 스케줄러(디스패처)의 작업(준비 → 실행)

### 타임아웃(time out)

- 프로세스는 자신에게 주어진 하나의 타임 슬라이스 동안 작업을 끝내지 못하면 실행 상태에서 다시 준비 상태로 돌아감(실행 → 준비)

## 프로세스와 스레드의 차이

### 프로세스와 스레드 정의

**프로세스**: 운영체제로부터 자원을 할당받은 **작업**의 단위

**스레드**: 프로세스가 할당받은 자원을 이용하는 **실행 흐름**의 단위

### 프로세스

프로그램: 파일이 저장장치에 저장되어 있지만 **메모리에는 올라가 있지 않은 정적 상태**

- **메모리에 올라가 있지 않은**: 운영체제가 프로그램에게 독립적인 메모리 공간을 할당하지 않은 상태 (모든 프로그램은 운영체제가 실행되기 위한 메모리 공간을 할당해줘야 실행 가능)
- **정적 상태**: 실행되지 않고 가만히 있는 상태
- 즉, 실행되지 않은 파일 자체를 가리키는 말로 윈도우의 .exe. 파일이나 맥의 .dmg 파일 ⇒ 코드 덩어리

프로그램을 실행하는 순간 파일은 컴퓨터 메모리에 올라가게 되고 동적 상태가 됨 ⇒ 프로세스

<aside>
💡 프로그램은 코드 덩어리 파일, 프로세스는 프로그램을 실행한 것

</aside>
<br>
과거에는 프로그램 당 하나의 프로세스만 사용하였지만, 시간이 흐를수록 프로그램이 복잡해지고 프로세스 하나로만 사용해서 프로그램을 실행하기에 벅찬 상태가 됨

⇒ 운영체제는 안전성을 위해 프로세스마다 자신에게 할당된 메모리 내의 정보만 접근할 수 있도록 제약을 두었고 이를 벗어나는 정보에 접근하려면 오류가 발생

⇒ 프로세스보다 더 작은 실행 단위 개념이 필요하게 되었고 이것이 **“스레드”**

### 스레드

프로세스와는 다르게 스레드 간 메모리를 공유하며 작동

스레드끼리 프로세스의 자원을 공유하며 프로세스 실행 흐름의 일부가 됨

프로그램이 코드 덩어리라면, 스레드는 코드 내의 선언된 함수들이 됨

<aside>
💡 스레드는 프로세스의 코드에 정의된 절차에 따라 실행되는 특정한 수행 경로

</aside>
<br>

### 그래서 프로세스와 스레드 뭐 ?????

운영체제는 **프로세스**마다 각각 독립된 메모리 영역을 Code/Data/Stack/Heap의 형식으로 할당

**독립된 메모리 영역을 할당**해주기 때문에 **프로세스**는 다른 프로세스의 변수, 자료에 접근 불가능

하지만 !!! 스레드는 메모리를 서로 공유 가능

프로세스가 할당받은 메모리 영역 내에서 **스택 형식으로 할당된 메모리 영역은 따로 할당**받고, 나머지 **코드/데이터/힙 형식으로 할당된 메모리 영역 공유**

한 프로세스를 실행하다가 오류가 발생해서 프로세스가 강제 종료된다면, 다른 프로세스에게 아무런 영향이 없다. (공유하고 있는 파일을 손상시키는 경우가 아니라면)

하지만 스레드의 경우 코드/데이터/힙 영역의 내용을 공유하기 때문에 어떤 스레드 하나에서 오류가 발생한다면 같은 프로세스 내의 다른 스레드 모두가 강제로 종료됨

**스레드**는 흐름의 단위, 정확히는 **CPU 입장에서 최소 작업 단위**가 됨

운영체제는 이렇게 작은 단위까지 직접 작업하지 않기 때문에 **운영체제 관점에서는 프로세스가 최소 작업 단위**

### 정말 다른 프로세스의 정보에 접근할 수 없을까 ???

- 가능함 - 단순히 CPU 레지스터 교체뿐만 아니라 RAM과 CPU 사이의 캐시 메모리까지 초기화되기 때문에 자원 부담이 큼
- IPC(Inter-Process Communication)
- LPC(Local inter-Process Communication)
- 별도로 공유 메모리를 만들어 정보를 주고받도록 설정

## 멀티스레드

### 멀티태스킹

- 하나의 운영체제 안에서 여러 프로세스가 실행되는 것

### 멀티스레드

- 하나의 프로세스가 여러 작업을 여러 스레드를 사용하여 동시에 처리하는 것

### 멀티스레드 장점

- Context-Switching 할 때 공유하고 있는 메모리만큼의 메모리 자원을 아낄 수 있음
- 스레드는 프로세스 내의 스택영역을 제외한 모든 메모리를 공유하기 때문에 통신의 부담이 적어 응답 시간이 빠름

### 멀티스레드 단점

- 스레드 하나가 프로세스 내 자원을 망쳐버린다면 모든 프로세스가 종료될 수 밖에 없음
- 자원을 공유하기 때문에 필연적으로 **동기화 문제(Synchronization Issue)**가 발생할 수 밖에 없음
- 동기화 문제: 멀티스레드 사용 시 각각의 스레드 중 어떤 것이 어떤 순서로 실행될지 알 수 없음. 만약 A 스레드가 어떤 자원을 사용하다가 B 스레드로 제어권이 넘어간 후 B 스레드가 해당 자원을 수정했을 때, 다시 제어권을 받은 A 스레드가 해당 자원에 접근하지 못하거나 바꾸니 자원에 접근하게 되는 오류 발생 ⇒ 여러 스레드가 함께 전역 변수를 사용할 경우 발생할 수 있는 충돌

## 스케줄러

### 프로세스를 스케줄링하기 위한 Queue

- **Job Queue**
  - 현재 시스템 내에 있는 모든 프로세스의 집합
- **Ready Queue**
  - 현재 메모리 내에 있으면서 CPU를 잡아 실행되기 기다리는 프로세스의 집합
- **Device Queue**
  - Device I/O 작업을 대기하고 있는 프로세스의 집합

**각각의 Queue에 프로세스들을 제어하는 스케줄러**

### 장기 스케줄러(Long-term scheduler or job scheduler)

- 한정된 메모리에 많은 프로세스들이 한꺼번에 올라올 경우, 대용량 메모리(ex. 디스크)에 임시로 저장됨
- 이 pool에 저장되어있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할
- 메모리와 디스크 사이의 스케줄링 담당
- 프로세스에 메모리(및 각종 리소스)를 할당
- 실행중인 프로세스의 수(degree of Multiprogramming) 제어
- 프로세스의 상태(new ⇒ ready)

메모리에 프로그램이 너무 많이 올라가도, 너무 적게 올라가도 성능이 좋지 않음

time sharing system에서는 장기 스케줄러가 없음 → 곧바로 메모리에 올라가 ready 상태가 됨

### 단기 스케줄러(Short-term scheduler or CPU scheduler)

- CPU와 메모리 사이의 스케줄링 담당
- Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정
- 프로세스에 CPU를 할당(scheduler dispatch)
- 프로세스의 상태 (ready → running → waiting → ready)

### 중기 스케줄러(Medium-term scheduler or Swapper)

- 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 보냄(swapping)
- 프로세스에게서 메모리를 deallocate
- degree of Multiprogramming 제어
- 프로세스의 상태(ready → suspended)

suspended(stopped) : 외부적인 이유로 프로세스의 수행이 정지된 상태, 메모리에서 내려간 상태. 프로세스 전부 디스크로 swap out 됨.
blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 ready state로 돌아갈 수 있지만 suspended(stopped) 상태는 외부적인 이유이기 때문에 스스로 돌아갈 수 없음

## CPU 스케줄러

### FCFS 스케줄링

- 비선점형 알고리즘
- First Come First Served 스케줄링
- 프로세스가 준비 큐에 도착한 순서대로 CPU에 할당하는 비선점형 방식, 선입선출 스케줄링
- 한 프로세스가 끝나야 다음 프로세스 실행 가능
- 큐는 하나, 모든 프로세스의 우선 순위는 동일
- 단순하고 공평하지만, 처리 시간이 긴 프로세스가 CPU를 차지하면 다른 프로세스들은 계속 기다려야 하기 때문에 시스템의 효율성이 떨어지는 문제 발생 ⇒ 콘보이 효과(or 호위 효과)
- 또한, 현재 작업중인 프로세스가 입출력 작업을 요청하는 경우 CPU가 작업하지 않고 쉬는 시간이 많아져 작업 효율이 떨어짐

### SJF 스케줄링

- 비선점형 알고리즘
- Shortest Job First 스케줄링
- 준비 큐에 있는 프로세스 중에서 실행 시간이 가장 짧은 작업부터 CPU를 할당하는 비선점형 방식, 최단 프로세스 우선 스케줄링
- 프로세스에 CPU를 배정할 때 시간이 오래 걸리는 작업이 앞에 있고 간단한 작업이 뒤에 있으면 그 순서를 바꾸어 실행(FCFS의 콘보이 효과 완화 → 시스템 효율성 up)
- 작은 작업을 먼저 실행하기 때문에 시스템 효율성이 좋음
- 하지만 다음과 같은 이유로 사용이 어려움
  - 운영체제가 프로세스의 종료 시간을 정확하게 예측하기 어려움
    - 프로세스가 자신의 작업 시간을 운영체제에 알리도록 함
  - 공평하지 못함 - 작업 시간이 긴 프로세스의 경우 계속 연기되어 아사 현상(또는 무한 봉쇄 현상)이 발생, 작업 시간이 길다는 이유만으로 계속 뒤로 밀려 공평성에 어긋남
    - 프로세스가 양보할 수 있는 상한선을 정하는 방식인 에이징으로 완화

### HRN 스케줄링

- 비선점형 알고리즘
- Highest Response Ratio Next 스케줄링
- SJF 스케줄링에서 발생할 수 있는 아사 현상을 해결하기 위해 만들어진 비선점형 방식, 최고 응답률 우선 스케줄링
- SJF 스케줄링은 프로세스의 실행 시간이 판단 기준이지만, HRN 스케줄링은 기다린 시간과 CPU 사용 시간을 고려하여 우선권이 주어지는 방식

    <aside>
    💡 우선 순위 = (대기시간 + CPU 사용 시간) / CPU 사용시간
    </aside>

- 실행 시간이 짧은 프로세스의 우선 순위를 높게 설정하면서도 대기 시간도 고려하여 아사 현상을 완화
- 대기 시간이 긴 프로세스의 우선 순위를 높임으로써 CPU 할당받을 확률을 높이지만 여전히 공평성이 위배되어 SJF와 마찬가지로 잘 사용되지 않음

### Round Robin 스케줄링

- 선점형 알고리즘
- 한 프로세스가 할당받은 시간(타임 슬라이스)동안 작업을 하다가 완료하지 못하면 큐의 맨 뒤로 가서 자기 차례를 기다리는 방식
- 각 프로세스마다 CPU를 사용할 수 있는 최대 시간이 정해져있음(타임 슬라이스가 있음)
- 하지만 라운드 로빈 스케줄링은 문맥 교환 시간이 추가됨, 타임 슬라이스를 적절히 설정해야 함 → 타임 슬라이스 크기는 프로세스의 반응 시간과 시스템 전체 성능에도 영향
- 타임 슬라이스가 너무 클 경우 하나의 작업이 끝나면 다음 작업이 시작되는 것처럼 보이고 FCFS와 다를게 없어진다.
- 타임 슬라이스가 너무 작은 경우 사용자는 여러 프로그램이 동시에 실행되는 것처럼 느낄 것, 하지만 시스템의 전반적인 성능이 떨어지고 문맥 교환이 너무 자주 일어나 문맥 교환에 걸리는 시간이 실제 작업 시간보다 상대적으로 커지며 낭비하게 됨
- 타임 슬라이스는 되도록 작게 설정하되 문맥 교환에 걸리는 시간을 고려하여 적당한 크기로 설정

### SRT 우선 스케줄링

- 선점형 알고리즘
- Shortest Remaining Time 스케줄링
- SJF 스케줄링과 라운드 로빈 스케줄링을 혼합한 방식, 최소 잔류 시간 우선 스케줄링
- 라운드 로빈 스케줄링 방식을 사용하는데, CPU를 할당받을 프로세스를 선택할 때 남아있는 작업 시간이 가장 적은 프로세스 선택
- 하지만 현재 실행중인 프로세스와 큐에 있는 프로세스의 남은 시간을 주기적으로 계산하고, 남은 시간이 더 적은 프로세스와 문맥 교환을 해야하므로 작업이 추가됨
- 운영체제가 프로세스의 종료 시간을 예측하기 어렵고 아사 현상이 발생할 수 있음

## Sync, Async

### Sync

- 메소드를 실행시킴과 동시에 반환값이 기대되는 경우
- 실행되었을 때 값이 반환되기 전까지 blocking 되어있음

### Async

- blocking 되지 않고 event queue에 넣거나 background thread에게 해당 task를 위임하고 다음 코드를 실행하여 기대되는 값이 바로 반환되지 않음
